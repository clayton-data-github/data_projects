{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\2923858804.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method='ffill')\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\2923858804.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method='ffill')\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\2923858804.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method='ffill')\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\2923858804.py:49: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  amenities_median = df.groupby('AgeBin')[amenities].median()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination',\n",
       "       'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa',\n",
       "       'VRDeck', 'Name', 'Transported', 'group_num', 'ppl_num', 'max_num',\n",
       "       'ticket_Earth55 Cancri e', 'ticket_EarthPSO J318.5-22',\n",
       "       'ticket_EarthTRAPPIST-1e', 'ticket_Europa55 Cancri e',\n",
       "       'ticket_EuropaPSO J318.5-22', 'ticket_EuropaTRAPPIST-1e',\n",
       "       'ticket_Mars55 Cancri e', 'ticket_MarsPSO J318.5-22',\n",
       "       'ticket_MarsTRAPPIST-1e', 'cabin_class', 'cabin_row',\n",
       "       'sum_expense', 'cabin_class_A', 'cabin_class_B', 'cabin_class_C',\n",
       "       'cabin_class_D', 'cabin_class_E', 'cabin_class_F', 'cabin_class_G',\n",
       "       'cabin_class_T', 'cabin_side_P', 'cabin_side_S'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_csv_path = 'train.csv'\n",
    "df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Splitting the PassengerId into group_num and ppl_num\n",
    "df[['group_num', 'ppl_num']] = df['PassengerId'].str.split('_', expand=True)\n",
    "\n",
    "# Finding the maximum number of people per group\n",
    "group_max = df.groupby('group_num')['ppl_num'].max().reset_index(name='max_num')\n",
    "df = pd.merge(df, group_max, on='group_num', how='left')\n",
    "df['max_num'] = df['max_num'].astype(int)\n",
    "\n",
    "# Generating a 'ticket' feature\n",
    "df['ticket'] = df['HomePlanet'] + df['Destination']\n",
    "\n",
    "# Getting dummies\n",
    "df = pd.get_dummies(df, columns=['ticket'])\n",
    "\n",
    "# Splitting the Cabin into class, row, and side\n",
    "df[['cabin_class', 'cabin_row', 'cabin_side']] = df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "# Function to fill null values in HomePlanet and Destination based on group_num\n",
    "def fill_based_on_group(df, column):\n",
    "    # Sort by group_num for efficient forward/backward filling within groups\n",
    "    df = df.sort_values(by=['group_num', 'ppl_num'])\n",
    "    # Forward fill and backward fill within each group\n",
    "    df[column] = df.groupby('group_num')[column].ffill().bfill()\n",
    "    # For any remaining, fill with the previous row's value\n",
    "    df[column] = df[column].fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "# Filling nulls in cabin information using the same method as for HomePlanet and Destination\n",
    "df = fill_based_on_group(df, 'cabin_class')\n",
    "df = fill_based_on_group(df, 'cabin_row')\n",
    "df = fill_based_on_group(df, 'cabin_side')\n",
    "\n",
    "# Fill VIP nulls with False\n",
    "df['VIP'] = df['VIP'].fillna(False)\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "# Creating age bins\n",
    "df['AgeBin'] = pd.cut(df['Age'], bins=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100], right=False)\n",
    "\n",
    "# Amenities columns to fill NA based on age bins\n",
    "amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# Calculate median for each age bin and amenity\n",
    "amenities_median = df.groupby('AgeBin')[amenities].median()\n",
    "\n",
    "# Function to fill NA in amenities based on age bin\n",
    "def fill_amenities_na(row, amenities, amenities_median):\n",
    "    for amenity in amenities:\n",
    "        if pd.isna(row[amenity]):\n",
    "            if row['CryoSleep'] == True:\n",
    "                fill_value = 0\n",
    "            else:\n",
    "                age_bin = row['AgeBin']\n",
    "                fill_value = amenities_median.loc[age_bin, amenity]\n",
    "            row[amenity] = fill_value\n",
    "    return row\n",
    "\n",
    "# Apply the function to fill NA values in amenities\n",
    "df = df.apply(lambda row: fill_amenities_na(row, amenities, amenities_median), axis=1)\n",
    "\n",
    "# Drop the temporary AgeBin column\n",
    "df.drop('AgeBin', axis=1, inplace=True)\n",
    "df['sum_expense'] = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "\n",
    "cabin_class_dummies = pd.get_dummies(df['cabin_class'], prefix='cabin_class')\n",
    "cabin_side_dummies = pd.get_dummies(df['cabin_side'], prefix='cabin_side')\n",
    "\n",
    "# Concatenating the dummy columns to the original dataframe\n",
    "df = pd.concat([df, cabin_class_dummies, cabin_side_dummies], axis=1)\n",
    "\n",
    "# Dropping the original 'cabin_class' and 'cabin_side' columns as corrected\n",
    "df.drop('cabin_side', axis=1, inplace=True)\n",
    "# Show the processed DataFrame structure\n",
    "df.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use\n",
    "columns = ['PassengerId', 'HomePlanet','Cabin', 'Destination','Name','cabin_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = df.drop(columns, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert type to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = df_01.astype({col: 'int' for col in df_01.select_dtypes('bool').columns})\n",
    "\n",
    "for col in df_01.columns:\n",
    "    if df_01[col].dtype == 'object':\n",
    "        df_01[col] = pd.to_numeric(df_01[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_try_feature = df_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_try_feature['AgeBin'] = pd.cut(df_try_feature['Age'], bins=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100], right=False)\n",
    "df_try_feature['age_bin'] = df_try_feature['AgeBin'].astype(str)\n",
    "age_bin_dummies = pd.get_dummies(df_try_feature['age_bin'], prefix='age_bin')\n",
    "df_try_feature = pd.concat([df_try_feature, age_bin_dummies], axis=1)\n",
    "df_try_feature[\"cabin_class\"] = df[\"cabin_class\"]\n",
    "df_try_feature[\"cabin_max\"] = df_try_feature[\"cabin_class\"] + df_try_feature['max_num'].astype(str)\n",
    "cabin_max_bin_dummies = pd.get_dummies(df_try_feature['cabin_max'], prefix='cabin_max')\n",
    "df_try_feature = pd.concat([df_try_feature, cabin_max_bin_dummies], axis=1)\n",
    "\n",
    "df_try_feature.drop('AgeBin', axis=1, inplace=True)\n",
    "df_try_feature.drop('age_bin', axis=1, inplace=True)\n",
    "df_try_feature.drop('cabin_class', axis=1, inplace=True)\n",
    "df_try_feature.drop('cabin_max', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_try_feature = df_try_feature.astype({col: 'int' for col in df_try_feature.select_dtypes('bool').columns})\n",
    "\n",
    "for col in df_try_feature.columns:\n",
    "    if df_try_feature[col].dtype == 'object':\n",
    "        df_try_feature[col] = pd.to_numeric(df_try_feature[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_try_feature.drop('Transported', axis=1) \n",
    "y = df_try_feature['Transported']  \n",
    "\n",
    "X_traint, X_testt, y_traint, y_testt = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# voting tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.8243542435424355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "bagging_base = BaggingClassifier(\n",
    "    estimator=RandomForestClassifier(max_depth=40),  \n",
    "    max_features=1.0,  \n",
    "    max_samples=1.0,  \n",
    "    n_estimators=50,  \n",
    "    random_state=200\n",
    ")\n",
    "\n",
    "gb_base = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,  \n",
    "    max_depth=4,  \n",
    "    min_samples_split=6,  \n",
    "    n_estimators=200,  \n",
    "    subsample=0.8,  \n",
    "    random_state=200\n",
    ")\n",
    "rf_base = RandomForestClassifier(\n",
    "    max_depth=None, \n",
    "    min_samples_leaf=3,  \n",
    "    min_samples_split=9,  \n",
    "    n_estimators=650, \n",
    "    random_state=42\n",
    ")\n",
    "ada_base = AdaBoostClassifier(\n",
    "    estimator=RandomForestClassifier(max_depth=3), \n",
    "    learning_rate = 0.1, n_estimators = 100)\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_base),\n",
    "        ('gd', gb_base),\n",
    "        ('ada',ada_base)\n",
    "    ],\n",
    "    voting='hard' \n",
    ")\n",
    "\n",
    "#X_traint, X_testt, y_traint, y_testt\n",
    "\n",
    "voting_classifier.fit(X_traint, y_traint)\n",
    "voting_pred = voting_classifier.predict(X_testt)\n",
    "voting_accuracy = accuracy_score(y_testt, voting_pred)\n",
    "print(\"Voting Classifier Accuracy:\", voting_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new voting grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "### Define classifiers\n",
    "bagging_clf = BaggingClassifier(random_state=42)\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "ada_clf = AdaBoostClassifier(random_state=42, algorithm='SAMME')\n",
    "\n",
    "### Define a VotingClassifier with soft voting\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('bagging', bagging_clf),\n",
    "    ('rf', rf_clf),\n",
    "    ('gb', gb_clf),\n",
    "    ('ada', ada_clf)\n",
    "], voting='soft')\n",
    "\n",
    "### Parameter grids for each classifier\n",
    "param_grid = {\n",
    "    'bagging__n_estimators': [10, 50],\n",
    "    'bagging__max_samples': [0.5, 1.0],\n",
    "    'bagging__max_features': [0.5, 1.0],\n",
    "    'rf__n_estimators': [10, 50],\n",
    "    'rf__max_depth': [3, None],\n",
    "    'rf__min_samples_split': [2, 3],\n",
    "    'gb__n_estimators': [50, 100],\n",
    "    'gb__learning_rate': [0.01, 0.1],\n",
    "    'gb__max_depth': [3, 5],\n",
    "    'ada__n_estimators': [50, 100],\n",
    "    'ada__learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "### GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=voting_clf, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "### Fit the models\n",
    "grid_search.fit(X_traint, y_traint)\n",
    "\n",
    "### Best parameters\n",
    "print(\"Best parameters for Voting Classifier:\", grid_search.best_params_)\n",
    "\n",
    "### Best score\n",
    "print(\"Best score for Voting Classifier:\", grid_search.best_score_)\n",
    "\n",
    "voting_predictions = grid_search.best_estimator_.predict(X_testt)\n",
    "voting_accuracy = accuracy_score(y_testt, voting_predictions)\n",
    "print(f\"Accuracy for Voting Classifier: {voting_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\1403459662.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method='ffill')\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\1403459662.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method='ffill')\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\1403459662.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method='ffill')\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\1403459662.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method='ffill')\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\1403459662.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method='ffill')\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\1403459662.py:66: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  amenities_median = df.groupby('AgeBin')[amenities].median()\n",
      "C:\\Users\\a0989\\AppData\\Local\\Temp\\ipykernel_78932\\1403459662.py:131: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_use[c] = 0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "new_data = pd.read_csv('test_clean.csv')\n",
    "df = new_data.iloc[:,:-8]\n",
    "#test_csv_path = 'test.csv'\n",
    "#df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Splitting the PassengerId into group_num and ppl_num\n",
    "df[['group_num', 'ppl_num']] = df['PassengerId'].str.split('_', expand=True)\n",
    "\n",
    "# Finding the maximum number of people per group\n",
    "group_max = df.groupby('group_num')['ppl_num'].max().reset_index(name='max_num')\n",
    "df = pd.merge(df, group_max, on='group_num', how='left')\n",
    "df['max_num'] = df['max_num'].astype(int)\n",
    "\n",
    "# Function to fill null values in HomePlanet and Destination based on group_num\n",
    "def fill_based_on_group(df, column):\n",
    "    # Sort by group_num for efficient forward/backward filling within groups\n",
    "    df = df.sort_values(by=['group_num', 'ppl_num'])\n",
    "    # Forward fill and backward fill within each group\n",
    "    df[column] = df.groupby('group_num')[column].ffill().bfill()\n",
    "    # For any remaining, fill with the previous row's value\n",
    "    df[column] = df[column].fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "# Filling nulls in HomePlanet and Destination\n",
    "df = fill_based_on_group(df, 'HomePlanet')\n",
    "df = fill_based_on_group(df, 'Destination')\n",
    "\n",
    "# Generating a 'ticket' feature\n",
    "df['ticket'] = df['HomePlanet'] + df['Destination']\n",
    "\n",
    "# Getting dummies\n",
    "df = pd.get_dummies(df, columns=['ticket'])\n",
    "\n",
    "# Splitting the Cabin into class, row, and side\n",
    "df[['cabin_class', 'cabin_row', 'cabin_side']] = df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "# Filling nulls in cabin information using the same method as for HomePlanet and Destination\n",
    "df = fill_based_on_group(df, 'cabin_class')\n",
    "df = fill_based_on_group(df, 'cabin_row')\n",
    "df = fill_based_on_group(df, 'cabin_side')\n",
    "\n",
    "# Fill VIP nulls with False\n",
    "df['VIP'] = df['VIP'].fillna(False)\n",
    "\n",
    "# Fill Age nulls with a random int between 0 and 65\n",
    "np.random.seed(666)  # For reproducibility\n",
    "\n",
    "df['Age'] = df['Age'].fillna(pd.Series(np.random.randint(0, 67, size=len(df))))\n",
    "\n",
    "\n",
    "# df['CryoSleep'] = df['CryoSleep'].fillna(df['Transported'])\n",
    "df['sum_expense'] = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "df['CryoSleep'] = df['CryoSleep'].fillna(df['sum_expense'] == 0)\n",
    "\n",
    "# Fill CrpoSleep with False where expense is not 0\n",
    "df['CryoSleep'] = df['CryoSleep'].fillna(False)\n",
    "\n",
    "# Creating age bins\n",
    "df['AgeBin'] = pd.cut(df['Age'], bins=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100], right=False)\n",
    "\n",
    "# Amenities columns to fill NA based on age bins\n",
    "amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# Calculate median for each age bin and amenity\n",
    "amenities_median = df.groupby('AgeBin')[amenities].median()\n",
    "\n",
    "# Function to fill NA in amenities based on age bin\n",
    "def fill_amenities_na(row, amenities, amenities_median):\n",
    "    for amenity in amenities:\n",
    "        if pd.isna(row[amenity]):\n",
    "            if row['CryoSleep'] == True:\n",
    "                fill_value = 0\n",
    "            else:\n",
    "                age_bin = row['AgeBin']\n",
    "                fill_value = amenities_median.loc[age_bin, amenity]\n",
    "            row[amenity] = fill_value\n",
    "    return row\n",
    "\n",
    "# Apply the function to fill NA values in amenities\n",
    "df = df.apply(lambda row: fill_amenities_na(row, amenities, amenities_median), axis=1)\n",
    "\n",
    "# Drop the temporary AgeBin column\n",
    "df.drop('AgeBin', axis=1, inplace=True)\n",
    "df['sum_expense'] = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "\n",
    "cabin_class_dummies = pd.get_dummies(df['cabin_class'], prefix='cabin_class')\n",
    "cabin_side_dummies = pd.get_dummies(df['cabin_side'], prefix='cabin_side')\n",
    "\n",
    "# Concatenating the dummy columns to the original dataframe\n",
    "df = pd.concat([df, cabin_class_dummies, cabin_side_dummies], axis=1)\n",
    "\n",
    "# Dropping the original 'cabin_class' and 'cabin_side' columns as corrected\n",
    "df.drop('cabin_side', axis=1, inplace=True)\n",
    "# Show the processed DataFrame structure\n",
    "\n",
    "# use\n",
    "columns = ['PassengerId', 'HomePlanet','Cabin', 'Destination','Name','cabin_class']\n",
    "test = df.drop(columns, axis = 1)\n",
    "### convert type to numerical\n",
    "test = test.astype({col: 'int' for col in test.select_dtypes('bool').columns})\n",
    "\n",
    "for col in test.columns:\n",
    "    if test[col].dtype == 'object':\n",
    "        test[col] = pd.to_numeric(test[col])\n",
    "df_try_feature = test\n",
    "df_try_feature['AgeBin'] = pd.cut(df_try_feature['Age'], bins=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100], right=False)\n",
    "df_try_feature['age_bin'] = df_try_feature['AgeBin'].astype(str)\n",
    "age_bin_dummies = pd.get_dummies(df_try_feature['age_bin'], prefix='age_bin')\n",
    "df_try_feature = pd.concat([df_try_feature, age_bin_dummies], axis=1)\n",
    "df_try_feature[\"cabin_class\"] = df[\"cabin_class\"]\n",
    "df_try_feature[\"cabin_max\"] = df_try_feature[\"cabin_class\"] + df_try_feature['max_num'].astype(str)\n",
    "cabin_age_bin_dummies = pd.get_dummies(df_try_feature['cabin_max'], prefix='cabin_max')\n",
    "df_try_feature = pd.concat([df_try_feature, cabin_age_bin_dummies], axis=1)\n",
    "\n",
    "df_try_feature.drop('AgeBin', axis=1, inplace=True)\n",
    "df_try_feature.drop('age_bin', axis=1, inplace=True)\n",
    "df_try_feature.drop('cabin_class', axis=1, inplace=True)\n",
    "df_try_feature.drop('cabin_max', axis=1, inplace=True)\n",
    "\n",
    "df_try_feature = df_try_feature.astype({col: 'int' for col in df_try_feature.select_dtypes('bool').columns})\n",
    "\n",
    "for col in df_try_feature.columns:\n",
    "    if df_try_feature[col].dtype == 'object':\n",
    "        df_try_feature[col] = pd.to_numeric(df_try_feature[col])\n",
    "\n",
    "test_use = df_try_feature\n",
    "missing_cols = set(X_traint.columns) - set(test_use.columns)\n",
    "\n",
    "for c in missing_cols:\n",
    "    test_use[c] = 0\n",
    "\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "test_use = test_use[X_traint.columns]\n",
    "\n",
    "\n",
    "test_pred = voting_classifier.predict(test_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 38 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   PassengerId                 4277 non-null   object \n",
      " 1   HomePlanet                  4277 non-null   object \n",
      " 2   CryoSleep                   4277 non-null   object \n",
      " 3   Cabin                       4177 non-null   object \n",
      " 4   Destination                 4277 non-null   object \n",
      " 5   Age                         4277 non-null   float64\n",
      " 6   VIP                         4277 non-null   bool   \n",
      " 7   RoomService                 4277 non-null   float64\n",
      " 8   FoodCourt                   4277 non-null   float64\n",
      " 9   ShoppingMall                4277 non-null   float64\n",
      " 10  Spa                         4277 non-null   float64\n",
      " 11  VRDeck                      4277 non-null   float64\n",
      " 12  Name                        4144 non-null   object \n",
      " 13  group_num                   4277 non-null   object \n",
      " 14  ppl_num                     4277 non-null   object \n",
      " 15  max_num                     4277 non-null   int64  \n",
      " 16  ticket_Earth55 Cancri e     4277 non-null   bool   \n",
      " 17  ticket_EarthPSO J318.5-22   4277 non-null   bool   \n",
      " 18  ticket_EarthTRAPPIST-1e     4277 non-null   bool   \n",
      " 19  ticket_Europa55 Cancri e    4277 non-null   bool   \n",
      " 20  ticket_EuropaPSO J318.5-22  4277 non-null   bool   \n",
      " 21  ticket_EuropaTRAPPIST-1e    4277 non-null   bool   \n",
      " 22  ticket_Mars55 Cancri e      4277 non-null   bool   \n",
      " 23  ticket_MarsPSO J318.5-22    4277 non-null   bool   \n",
      " 24  ticket_MarsTRAPPIST-1e      4277 non-null   bool   \n",
      " 25  cabin_class                 4277 non-null   object \n",
      " 26  cabin_row                   4277 non-null   object \n",
      " 27  sum_expense                 4277 non-null   float64\n",
      " 28  cabin_class_A               4277 non-null   bool   \n",
      " 29  cabin_class_B               4277 non-null   bool   \n",
      " 30  cabin_class_C               4277 non-null   bool   \n",
      " 31  cabin_class_D               4277 non-null   bool   \n",
      " 32  cabin_class_E               4277 non-null   bool   \n",
      " 33  cabin_class_F               4277 non-null   bool   \n",
      " 34  cabin_class_G               4277 non-null   bool   \n",
      " 35  cabin_class_T               4277 non-null   bool   \n",
      " 36  cabin_side_P                4277 non-null   bool   \n",
      " 37  cabin_side_S                4277 non-null   bool   \n",
      "dtypes: bool(20), float64(7), int64(1), object(10)\n",
      "memory usage: 685.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2 = pd.read_csv('test.csv')\n",
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Transported\n",
       "0        0013_01       False\n",
       "1        0018_01       False\n",
       "2        0019_01        True\n",
       "3        0021_01        True\n",
       "4        0023_01        True\n",
       "...          ...         ...\n",
       "4272     9266_02        True\n",
       "4273     9269_01       False\n",
       "4274     9271_01        True\n",
       "4275     9273_01        True\n",
       "4276     9277_01        True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2 = pd.read_csv('test.csv')\n",
    "ans = df_test2['PassengerId']\n",
    "ans_df = pd.DataFrame({\n",
    "    'PassengerId': ans\n",
    "})\n",
    "ans_df[\"Transported\"] = test_pred\n",
    "ans_df['Transported'] = ans_df['Transported'].replace({1: 'True', 0: 'False'})\n",
    "ans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df.to_csv('welovemrchow.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
